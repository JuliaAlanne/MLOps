# Desafio de Classifica√ß√£o Bin√°ria com PyTorch 

## üìå Descri√ß√£o do Projeto

Este projeto √© um desafio pr√°tico de classifica√ß√£o bin√°ria implementado em PyTorch, focado em explorar o impacto de diferentes configura√ß√µes na performance e decis√£o de um modelo de **Regress√£o Log√≠stica**.

O principal objetivo foi analisar como a **separabilidade dos dados (ru√≠do)** e a **escolha da fun√ß√£o de perda (Loss Function)** afetam a converg√™ncia do modelo e as m√©tricas de avalia√ß√£o.

### üõ†Ô∏è Requisitos T√©cnicos

1.  **Modelo:** Regress√£o Log√≠stica implementada em PyTorch.
2.  **Arquitetura:** Utiliza√ß√£o obrigat√≥ria da classe `Architecture` fornecida em aula.
3.  **Dados:** Tr√™s datasets sint√©ticos gerados com `sklearn.datasets` (`make_classification`, `make_circles`, `make_moons`), simulando diferentes n√≠veis de separabilidade e complexidade.
4.  **Fun√ß√µes de Perda (Loss Functions):** An√°lise e compara√ß√£o entre `nn.BCELoss` e `nn.BCEWithLogitsLoss`.

---
## üî¨ Experimentos Realizados

O modelo de Regress√£o Log√≠stica foi treinado por 100 √©pocas em tr√™s datasets normalizados.

### 1. An√°lise de Ru√≠do e Complexidade dos Dados

Foram utilizados tr√™s datasets com diferentes caracter√≠sticas de separabilidade, simulando um aumento na complexidade e ru√≠do dos dados.

![Datasets (noise 0.1)](img/d.png)

![Datasets (noise 0.3)](img/d_.png)



| Dataset | Fun√ß√£o de Gera√ß√£o | Separabilidade / Ru√≠do | Desempenho Esperado da Reg. Log√≠stica |
| :--- | :--- | :--- | :--- |
| **Dataset 1** | `make_classification` | Linearmente separ√°vel (Alta Sep.) | Excelente |
| **Dataset 2** | `make_circles` | N√£o-linear (Ru√≠do M√©dio) | Ruim (A fronteira linear √© inadequada) |
| **Dataset 3** | `make_moons` | N√£o-linear (Baixo Ru√≠do) | Bom (O modelo encontra uma fronteira linear aceit√°vel para parte dos dados) |

**Observa√ß√µes sobre Converg√™ncia (Baseado nos Gr√°ficos de Perda):**

* **Dataset 1:** A perda (Loss) atingiu o valor mais baixo e convergiu rapidamente, refletindo a natureza linearmente separ√°vel dos dados e a adequa√ß√£o do modelo.
![Gr√°ficos de Perda do Dataset 1](img/loss_dataset_01.png)

* **Dataset 2 (Circles):** A perda se manteve alta e a converg√™ncia foi lenta/inexistente. Isso demonstra a inefic√°cia de um modelo linear (Regress√£o Log√≠stica) para separar um dataset de c√≠rculos conc√™ntricos.
![Gr√°ficos de Perda do Dataset 2](img/loss_dataset_02.png)

* **Dataset 3 (Moons):** A perda diminuiu significativamente e estabilizou em um valor baixo/m√©dio. Embora o dataset seja n√£o-linear, o modelo consegue tra√ßar uma fronteira linear que otimiza a separa√ß√£o global, resultando em boa performance.
![Gr√°ficos de Perda do Dataset 3](img/loss_dataset_03.png)

**Discuss√£o sobre Trade-off:**
**A diferen√ßa de performance entre o Dataset 1 e os Datasets 2 (circles) ou 3 (moons) revela que a Regress√£o Log√≠stica (modelo linear) √© inadequada para dados cuja separa√ß√£o exige uma fronteira curva ou complexa. O baixo desempenho no Dataset 2 (circles), por exemplo, demonstra claramente que a fronteira de decis√£o linear n√£o consegue generalizar a rela√ß√£o n√£o-linear entre as classes.**

*Regress√£o Log√≠stica modela a probabilidade usando uma combina√ß√£o linear das caracter√≠sticas, resultando em uma fronteira de decis√£o sempre reta (uma hiperp√©lace no espa√ßo de caracter√≠sticas).

*Dataset 2 (make_circles): A fronteira de decis√£o ideal √© um c√≠rculo (n√£o-linear). Como o modelo linear n√£o consegue tra√ßar essa curva, ele tenta tra√ßar a melhor linha reta poss√≠vel, o que resulta em uma acur√°cia pr√≥xima de 50% (aleat√≥ria), evidenciando a limita√ß√£o do modelo.

*Dataset 3 (make_moons): Embora seja n√£o-linear, o baixo ru√≠do (noise=0.1) permitiu que o modelo encontrasse uma linha reta que, por sorte, separa bem uma parte significativa das classes, resultando em um desempenho surpreendentemente bom (~91.7% de acur√°cia).

### 2. Matrizes de Confus√£o e M√©tricas de Desempenho

As m√©tricas foram calculadas no conjunto de valida√ß√£o (`X_val`).

| Dataset | Acur√°cia | Precis√£o | Recall |
| :--- | :--- | :--- | :--- |
| **Dataset 1** | **[0.050]** | **[0.097]** | **[0.094]** |
| **Dataset 2** | **[0.583]** | **[0.567]** | **[0.586]** |
| **Dataset 3** | **[0.917]** | **[0.900]** | **[0.931]** |

**Matrizes de Confus√£o (Screenshots/Plots)**

![Plot das Matrizes de Confus√£o para cada Dataset](img/plots_matriz_confusao.png)

**[PREENCHER - Adicione um plot ou screenshot da matriz de confus√£o. Ex: O Dataset 1, embora linear, resultou em uma matriz ruim (previs√µes invertidas), o que sugere que o threshold `0.5` ou a normaliza√ß√£o/escala do `make_classification` pode ter invertido as classes 0 e 1, ou o modelo n√£o convergiu para o lado correto da fronteira. √â importante mencionar se o resultado de 5% de acur√°cia no Dataset 1 √© esperado ou se indica um problema (e explicar se o problema √© o threshold).]**

### 3. Compara√ß√£o das Fun√ß√µes de Perda (`BCELoss` vs `BCEWithLogitsLoss`)

**[OBSERVA√á√ÉO: Esta se√ß√£o deve ser expandida no seu notebook e os resultados (m√©tricas e gr√°ficos de perda) devem ser inclu√≠dos para total ader√™ncia ao desafio.]**

| Fun√ß√£o de Perda | Entrada Esperada | Estabilidade Num√©rica | Configura√ß√£o do Modelo |
| :--- | :--- | :--- | :--- |
| **`nn.BCELoss`** | **Probabilidades** (valores entre 0 e 1, ap√≥s `Sigmoid`). | **Menor** (Vulner√°vel a `log(0)`). | Exige `nn.Sequential(..., nn.Sigmoid())` |
| **`nn.BCEWithLogitsLoss`** | **Logits** (sa√≠das brutas $\in \mathbb{R}$). | **Maior** (Usa o *log-sum-exp trick*). | Exige `nn.Sequential(nn.Linear(...))` (sem `Sigmoid`) |

#### Logits vs. Probabilidades e Estabilidade

1.  **Diferen√ßa de Entrada:**
    * **`nn.BCELoss()`** calcula o BCE (Binary Cross Entropy) e **requer** que as sa√≠das do modelo sejam **probabilidades** (entre $0$ e $1$).
    * **`nn.BCEWithLogitsLoss()`** combina a camada **Sigmoid** e a fun√ß√£o **`BCELoss`** em uma √∫nica opera√ß√£o. Ela espera **logits** (pontua√ß√µes brutas do `nn.Linear`) como entrada.

2.  **Estabilidade Num√©rica:**
    * √â altamente recomendado usar **`nn.BCEWithLogitsLoss()`** para maior **estabilidade num√©rica**.
    * A combina√ß√£o manual de `Sigmoid` + `BCELoss` √© suscet√≠vel a erros de ponto flutuante (*underflow* ou *overflow*), especialmente quando os *logits* s√£o muito grandes (positivos ou negativos).
    * Valores de *logits* muito extremos podem fazer com que a `Sigmoid` produza valores exatamente $0$ ou $1$. Quando o $\log$ (logaritmo) √© aplicado a um valor muito pr√≥ximo de $0$ (parte do c√°lculo do BCE), o resultado pode se tornar $\pm\infty$ ou `NaN` (Not a Number), desestabilizando o treinamento.
    * `nn.BCEWithLogitsLoss()` supera isso usando um m√©todo mais est√°vel (*log-sum-exp trick*), garantindo c√°lculos precisos mesmo com *logits* extremos.


---

## üé• Apresenta√ß√£o em V√≠deo

* **Link para o V√≠deo (Loom/YouTube):** `[PREENCHER O LINK DO V√çDEO]`
