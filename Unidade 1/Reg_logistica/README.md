# Desafio de Classifica√ß√£o Bin√°ria com PyTorch (B√¥nus - Unidade 1)

## üìå Descri√ß√£o do Projeto

Este projeto √© um desafio pr√°tico de classifica√ß√£o bin√°ria implementado em PyTorch, focado em explorar o impacto de diferentes configura√ß√µes na performance e decis√£o de um modelo de **Regress√£o Log√≠stica**.

O principal objetivo foi analisar como a **separabilidade dos dados (ru√≠do)** e a **escolha da fun√ß√£o de perda (Loss Function)** afetam a converg√™ncia do modelo e as m√©tricas de avalia√ß√£o.

### üõ†Ô∏è Requisitos T√©cnicos

1.  **Modelo:** Regress√£o Log√≠stica implementada em PyTorch.
2.  **Arquitetura:** Utiliza√ß√£o obrigat√≥ria da classe `Architecture` fornecida em aula.
3.  **Dados:** Tr√™s datasets sint√©ticos gerados com `sklearn.datasets` (`make_classification`, `make_circles`, `make_moons`), simulando diferentes n√≠veis de separabilidade e complexidade.
4.  **Fun√ß√µes de Perda (Loss Functions):** An√°lise e compara√ß√£o entre `nn.BCELoss` e `nn.BCEWithLogitsLoss`.

---

## üî¨ Experimentos Realizados

O modelo de Regress√£o Log√≠stica foi treinado por 100 √©pocas em tr√™s datasets normalizados.

### 1. An√°lise de Ru√≠do e Complexidade dos Dados

Foram utilizados tr√™s datasets com diferentes caracter√≠sticas de separabilidade, simulando um aumento na complexidade e ru√≠do dos dados.

| Dataset | Fun√ß√£o de Gera√ß√£o | Separabilidade / Ru√≠do | Desempenho Esperado da Reg. Log√≠stica |
| :--- | :--- | :--- | :--- |
| **Dataset 1** | `make_classification` | Linearmente separ√°vel (Alta Sep.) | Excelente |
| **Dataset 2** | `make_circles` | N√£o-linear (Ru√≠do M√©dio) | Ruim (A fronteira linear √© inadequada) |
| **Dataset 3** | `make_moons` | N√£o-linear (Baixo Ru√≠do) | Bom (O modelo encontra uma fronteira linear aceit√°vel para parte dos dados) |

**Observa√ß√µes sobre Converg√™ncia (Baseado nos Gr√°ficos de Perda):**

* **[PREENCHER - Analisar os gr√°ficos de perda (`fig1`, `fig2`, `fig3`)]**
* **Dataset 1:** A perda (Loss) atingiu o valor mais baixo e convergiu rapidamente, refletindo a natureza linearmente separ√°vel dos dados e a adequa√ß√£o do modelo.
* **Dataset 2 (Circles):** A perda se manteve alta e a converg√™ncia foi lenta/inexistente. Isso demonstra a inefic√°cia de um modelo linear (Regress√£o Log√≠stica) para separar um dataset de c√≠rculos conc√™ntricos.
* **Dataset 3 (Moons):** A perda diminuiu significativamente e estabilizou em um valor baixo/m√©dio. Embora o dataset seja n√£o-linear, o modelo consegue tra√ßar uma fronteira linear que otimiza a separa√ß√£o global, resultando em boa performance.

**Discuss√£o sobre Trade-off:**
**[PREENCHER - Discuta o que a diferen√ßa de performance entre o Dataset 1 e o Dataset 2 (circles) ou Dataset 3 (moons) revela sobre a Regress√£o Log√≠stica (modelo linear) e dados n√£o-lineares/ruidosos. Ex: O modelo linear tem dificuldade em generalizar quando a separabilidade n√£o √© uma linha reta, como visto nos `circles`.]**

### 2. Matrizes de Confus√£o e M√©tricas de Desempenho

As m√©tricas foram calculadas no conjunto de valida√ß√£o (`X_val`).

| Dataset | Acur√°cia | Precis√£o | Recall |
| :--- | :--- | :--- | :--- |
| **Dataset 1** | **[0.050]** | **[0.097]** | **[0.094]** |
| **Dataset 2** | **[0.583]** | **[0.567]** | **[0.586]** |
| **Dataset 3** | **[0.917]** | **[0.900]** | **[0.931]** |

**Matrizes de Confus√£o (Screenshots/Plots)**

![Plot das Matrizes de Confus√£o para cada Dataset](caminho/para/seus/plots_matriz_confusao.png)

**[PREENCHER - Adicione um plot ou screenshot da matriz de confus√£o. Ex: O Dataset 1, embora linear, resultou em uma matriz ruim (previs√µes invertidas), o que sugere que o threshold `0.5` ou a normaliza√ß√£o/escala do `make_classification` pode ter invertido as classes 0 e 1, ou o modelo n√£o convergiu para o lado correto da fronteira. √â importante mencionar se o resultado de 5% de acur√°cia no Dataset 1 √© esperado ou se indica um problema (e explicar se o problema √© o threshold).]**

### 3. Compara√ß√£o das Fun√ß√µes de Perda (`BCELoss` vs `BCEWithLogitsLoss`)

**[OBSERVA√á√ÉO: Esta se√ß√£o deve ser expandida no seu notebook e os resultados (m√©tricas e gr√°ficos de perda) devem ser inclu√≠dos para total ader√™ncia ao desafio.]**

| Fun√ß√£o de Perda | Entrada Esperada | Estabilidade Num√©rica | Configura√ß√£o do Modelo |
| :--- | :--- | :--- | :--- |
| **`nn.BCELoss`** | **Probabilidades** (valores entre 0 e 1, ap√≥s `Sigmoid`). | **Menor** (Vulner√°vel a `log(0)`). | Exige `nn.Sequential(..., nn.Sigmoid())` |
| **`nn.BCEWithLogitsLoss`** | **Logits** (sa√≠das brutas $\in \mathbb{R}$). | **Maior** (Usa o *log-sum-exp trick*). | Exige `nn.Sequential(nn.Linear(...))` (sem `Sigmoid`) |

#### Logits vs. Probabilidades e Estabilidade

1.  **Diferen√ßa de Entrada:**
    * **`nn.BCELoss()`** calcula o BCE (Binary Cross Entropy) e **requer** que as sa√≠das do modelo sejam **probabilidades** (entre $0$ e $1$).
    * **`nn.BCEWithLogitsLoss()`** combina a camada **Sigmoid** e a fun√ß√£o **`BCELoss`** em uma √∫nica opera√ß√£o. Ela espera **logits** (pontua√ß√µes brutas do `nn.Linear`) como entrada.

2.  **Estabilidade Num√©rica:**
    * √â altamente recomendado usar **`nn.BCEWithLogitsLoss()`** para maior **estabilidade num√©rica**.
    * A combina√ß√£o manual de `Sigmoid` + `BCELoss` √© suscet√≠vel a erros de ponto flutuante (*underflow* ou *overflow*), especialmente quando os *logits* s√£o muito grandes (positivos ou negativos).
    * Valores de *logits* muito extremos podem fazer com que a `Sigmoid` produza valores exatamente $0$ ou $1$. Quando o $\log$ (logaritmo) √© aplicado a um valor muito pr√≥ximo de $0$ (parte do c√°lculo do BCE), o resultado pode se tornar $\pm\infty$ ou `NaN` (Not a Number), desestabilizando o treinamento.
    * `nn.BCEWithLogitsLoss()` supera isso usando um m√©todo mais est√°vel (*log-sum-exp trick*), garantindo c√°lculos precisos mesmo com *logits* extremos.

---

## üé® Visualiza√ß√£o da Fronteira de Decis√£o

**[OBSERVA√á√ÉO: Esta se√ß√£o est√° ausente no notebook. Voc√™ deve gerar e incluir plots da fronteira de decis√£o aqui para cada um dos 3 datasets, comparando a fronteira de um dataset de baixo ru√≠do (Dataset 1) com um de alto ru√≠do (Dataset 2, Circles).]**

![Fronteira de Decis√£o - Dataset 1 (Baixo Ru√≠do)](caminho/para/plot_db_dataset1.png)
*Interpreta√ß√£o:* **[PREENCHER - Descrever o qu√£o bem a fronteira linear separa o Dataset 1 (deve ser quase perfeita).]**

![Fronteira de Decis√£o - Dataset 2 (Alto Ru√≠do/N√£o-linear)](caminho/para/plot_db_dataset2.png)
*Interpreta√ß√£o:* **[PREENCHER - Descrever por que a fronteira √© inadequada para o Dataset 2 (√© uma linha reta que falha em separar c√≠rculos conc√™ntricos).]**

---

## üé• Apresenta√ß√£o em V√≠deo

* **Link para o V√≠deo (Loom/YouTube):** `[PREENCHER O LINK DO V√çDEO]`
