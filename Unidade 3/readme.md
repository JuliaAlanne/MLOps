# üíª  Otimiza√ß√£o Avan√ßada em Deep Learning com PyTorch: Uma An√°lise aplicada ao Fashion-MNIST

Este reposit√≥rio cont√©m o c√≥digo, experimentos e visualiza√ß√µes desenvolvidas para a **Nota T√©cnica Aprofundada** do Cap√≠tulo 6 do livro *Deep Learning with PyTorch Step-by-Step*. O projeto aplica os conceitos de otimiza√ß√£o de redes neurais ao modelo CNN LeNet-like treinado no popular dataset **Fashion-MNIST**.

---

## üë©‚Äçüíª Autores
* **Julia Alanne Silvino dos Santos**
* **Pablo Durkheim Fernandes do Nascimento**

Este trabalho foi desenvolvido como projeto final da disciplina de **PROJETO DE SISTEMAS BASEADOS EM APRENDIZADO DE M√ÅQUINA**.

## üìÑ Nota T√©cnica e Objetivos

Voc√™ pode conferir a an√°lise detalhada, resultados e conclus√µes na nota t√©cnica publicada:

> **üîó Link para o Artigo no Medium:**
> [`Otimiza√ß√£o Avan√ßada em Deep Learning com PyTorch`](https://medium.com/@juliaalanne/otimiza%C3%A7%C3%A3o-avan%C3%A7ada-em-deep-learning-com-pytorch-uma-an%C3%A1lisem-aplicada-ao-fashion-mnist-8a0a7aa1095f?postPublishedType=repub)

### üéØ Objetivos T√©cnicos
O projeto tem como objetivo:

* Demonstrar a fun√ß√£o da **EWMA (Exponentially Weighted Moving Average)** no suavizamento de gradientes e o papel da **Corre√ß√£o de Vi√©s (Bias Correction)**.
* Comparar o desempenho e a trajet√≥ria do **SGD Simples**, **SGD com Momentum** e **SGD com Nesterov**.
* Visualizar os **Gradientes Adaptados do Adam** (Primeiro e Segundo Momento) em um gr√°fico de tr√™s pain√©is.
* Implementar e comparar diferentes **Learning Rate Schedulers** ($\text{StepLR}$ e $\text{LambdaLR}$) e analisar seu impacto em treinamentos curtos.

---
