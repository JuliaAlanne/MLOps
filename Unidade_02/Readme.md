## An√°lise e Visualiza√ß√£o de CNNs com Fashion-MNIST

Este projeto  foca na **constru√ß√£o, treinamento e an√°lise detalhada** de uma Rede Neural Convolucional (CNN) adaptada da arquitetura LeNet-like  para a classifica√ß√£o de imagens do dataset **Fashion-MNIST**.

A atividade principal √© utilizar *PyTorch Hooks* para capturar e visualizar as ativa√ß√µes internas (feature maps) das camadas da rede, entendendo como o modelo extrai caracter√≠sticas visuais para realizar a classifica√ß√£o multiclasse.

---

## üéØ Objetivo da Atividade

1.  **Adapta√ß√£o de Dados:** Configurar o carregamento e pr√©-processamento do dataset **Fashion-MNIST** (10 classes, imagens $28\times28$).
2.  **Constru√ß√£o da Arquitetura:** Implementar uma CNN de bloco √∫nico (similar √† LeNet-like), ajustando as dimens√µes de entrada e sa√≠da para o Fashion-MNIST.
3.  **Treinamento e M√©tricas:** Treinar o modelo usando o **Cross-Entropy Loss** e registrar as m√©tricas de perda e acur√°cia (treino/valida√ß√£o).
4.  **Inspe√ß√£o da Rede (Hooks):** Utilizar *PyTorch Hooks* para interceptar e capturar os tensores de sa√≠da (ativa√ß√µes) de cada camada da CNN.
5.  **Visualiza√ß√£o:** Gerar plots dos **filtros aprendidos** e dos **feature maps** intermedi√°rios.

---

## üíª Arquitetura da CNN

O modelo implementado segue a estrutura b√°sica de uma CNN, dividida em um **Featurizer** (extra√ß√£o de caracter√≠sticas) e um **Classifier** (tomada de decis√£o).

### 1. Detalhes da Camada

A arquitetura foi ajustada para aceitar o input $1\times28\times28$ do Fashion-MNIST:

| Camada (Module) | Tipo | Par√¢metros Chave | Sa√≠da (Output Shape) | Fun√ß√£o Principal |
| :--- | :--- | :--- | :--- | :--- |
| **Input** | Imagem | $1\times28\times28$ | $1\times28\times28$ | Imagem normalizada |
| `conv1` | `nn.Conv2d` | `kernel_size=5` | $1\times24\times24$ | Extra√ß√£o de bordas/texturas b√°sicas |
| `relu1` | `nn.ReLU` | - | $1\times24\times24$ | Introdu√ß√£o de n√£o-linearidade (zera valores negativos) |
| `maxp1` | `nn.MaxPool2d` | `kernel_size=2` | $1\times12\times12$ | Redu√ß√£o da dimensionalidade e invari√¢ncia de transla√ß√£o |
| `flatten` | `nn.Flatten` | - | $1\times144$ | Converte o feature map 2D em vetor 1D (Flattened Size = $12\times12=144$) |
| `fc1` | `nn.Linear` | `in=144`, `out=10` | $1\times10$ | Camada oculta de classifica√ß√£o |
| `relu2` | `nn.ReLU` | - | $1\times10$ | Ativa√ß√£o da camada oculta |
| `fc2` | `nn.Linear` | `in=10`, `out=10` | $1\times10$ | Camada de sa√≠da (logits para as 10 classes) |

### 2. Par√¢metros

* **Dataset:** Fashion-MNIST
* **Total de Classes:** 10
* **Total de Par√¢metros Trein√°veis:** 1910 (baixa complexidade, ideal para an√°lise)
* **Fun√ß√£o de Perda:** `nn.CrossEntropyLoss` (usando SGD) 

---

## üõ†Ô∏è Detalhes da Implementa√ß√£o

### 1. `Architecture` Class

A classe `Architecture` (no `CNN_FashionMNIST.ipynb`) foi mantida quase id√™ntica √† fornecida, com pequenos ajustes de compatibilidade.

### 2. Uso de Hooks

Os PyTorch Hooks foram registrados nas camadas de interesse (`conv1`, `relu1`, `maxp1`, `flatten`, `fc1`, `relu2`, `fc2`) para inspecionar os tensores de ativa√ß√£o **ap√≥s o forward pass** (`register_forward_hook`).

Isto permitiu:
* Visualizar o mapa de caracter√≠sticas gerado ap√≥s a convolu√ß√£o (`conv1`).
* Verificar o efeito da n√£o-linearidade (ReLU) ao zerar as ativa√ß√µes negativas.
* Observar o *downsampling* espacial do *feature map* ap√≥s o *pooling* (`maxp1`).

---

## üìä Resultados e An√°lise 


### 1. Curvas de Perda (Loss)

O modelo foi treinado por 10 √©pocas, alcan√ßando uma acur√°cia de valida√ß√£o de aproximadamente **84.32%**.



> **An√°lise da Converg√™ncia:**
> As curvas de perda de treino e valida√ß√£o diminu√≠ram rapidamente nas primeiras 5 √©pocas, convergindo para um plat√¥ em torno de 0.5. A perda de valida√ß√£o acompanhou de perto a perda de treino, indicando que o modelo generalizou bem e n√£o apresentou *overfitting* significativo. A baixa complexidade do modelo (poucos filtros) pode ter limitado a acur√°cia m√°xima, mas garantiu uma converg√™ncia est√°vel.

### 2. An√°lise dos Feature Maps



> **Interpreta√ß√£o Visual:**
> O **Filtro #0 da camada `conv1`** parece ter aprendido a detectar bordas verticais ou padr√µes angulares (como √© comum em filtros de baixo n√≠vel). O **Feature Map ap√≥s `conv1`** mostra essas bordas ativadas. Ap√≥s a **`relu1`**, todos os valores negativos foram zerados, resultando em ativa√ß√µes mais esparsas e um mapa mais escuro. Finalmente, a camada **`maxp1`** reduziu o tamanho do *feature map* (de $26\times26$ para $13\times13$), preservando as ativa√ß√µes mais fortes (brilhantes), o que √© vis√≠vel pela semelhan√ßa do padr√£o no mapa reduzido.

---

## üì∫ V√≠deo Explicativo

O v√≠deo a seguir demonstra o processo de desenvolvimento e detalha a an√°lise visual das ativa√ß√µes da rede:

[Link do V√≠deo]

`
