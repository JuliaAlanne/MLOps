## AnÃ¡lise e VisualizaÃ§Ã£o de CNNs com Fashion-MNIST

Este projeto  foca na **construÃ§Ã£o, treinamento e anÃ¡lise detalhada** de uma Rede Neural Convolucional (CNN) adaptada da arquitetura LeNet-like  para a classificaÃ§Ã£o de imagens do dataset **Fashion-MNIST**.

A atividade principal Ã© utilizar *PyTorch Hooks* para capturar e visualizar as ativaÃ§Ãµes internas (feature maps) das camadas da rede, entendendo como o modelo extrai caracterÃ­sticas visuais para realizar a classificaÃ§Ã£o multiclasse.

---

## ğŸ¯ Objetivo da Atividade

1.  **AdaptaÃ§Ã£o de Dados:** Configurar o carregamento e prÃ©-processamento do dataset **Fashion-MNIST** (10 classes, imagens $28\times28$).
2.  **ConstruÃ§Ã£o da Arquitetura:** Implementar uma CNN de bloco Ãºnico (similar Ã  LeNet-like), ajustando as dimensÃµes de entrada e saÃ­da para o Fashion-MNIST.
3.  **Treinamento e MÃ©tricas:** Treinar o modelo usando o **Cross-Entropy Loss** e registrar as mÃ©tricas de perda e acurÃ¡cia (treino/validaÃ§Ã£o).
4.  **InspeÃ§Ã£o da Rede (Hooks):** Utilizar *PyTorch Hooks* para interceptar e capturar os tensores de saÃ­da (ativaÃ§Ãµes) de cada camada da CNN.
5.  **VisualizaÃ§Ã£o:** Gerar plots dos **filtros aprendidos** e dos **feature maps** intermediÃ¡rios.

---

## ğŸ’» Arquitetura da CNN

O modelo implementado segue a estrutura bÃ¡sica de uma CNN, dividida em um **Featurizer** (extraÃ§Ã£o de caracterÃ­sticas) e um **Classifier** (tomada de decisÃ£o).

### 1. Detalhes da Camada

A arquitetura foi ajustada para aceitar o input $1\times28\times28$ do Fashion-MNIST:

| Camada (Module) | Tipo | ParÃ¢metros Chave | SaÃ­da (Output Shape) | FunÃ§Ã£o Principal |
| :--- | :--- | :--- | :--- | :--- |
| **Input** | Imagem | $1\times28\times28$ | $1\times28\times28$ | Imagem normalizada |
| `conv1` | `nn.Conv2d` | `kernel_size=5` | $1\times24\times24$ | ExtraÃ§Ã£o de bordas/texturas bÃ¡sicas |
| `relu1` | `nn.ReLU` | - | $1\times24\times24$ | IntroduÃ§Ã£o de nÃ£o-linearidade (zera valores negativos) |
| `maxp1` | `nn.MaxPool2d` | `kernel_size=2` | $1\times12\times12$ | ReduÃ§Ã£o da dimensionalidade e invariÃ¢ncia de translaÃ§Ã£o |
| `flatten` | `nn.Flatten` | - | $1\times144$ | Converte o feature map 2D em vetor 1D (Flattened Size = $12\times12=144$) |
| `fc1` | `nn.Linear` | `in=144`, `out=10` | $1\times10$ | Camada oculta de classificaÃ§Ã£o |
| `relu2` | `nn.ReLU` | - | $1\times10$ | AtivaÃ§Ã£o da camada oculta |
| `fc2` | `nn.Linear` | `in=10`, `out=10` | $1\times10$ | Camada de saÃ­da (logits para as 10 classes) |

### 2. ParÃ¢metros

* **Dataset:** Fashion-MNIST
* **Total de Classes:** 10
* **Total de ParÃ¢metros TreinÃ¡veis:** 1910 (baixa complexidade, ideal para anÃ¡lise)
* **FunÃ§Ã£o de Perda:** `nn.CrossEntropyLoss` (usando SGD) 

---

## ğŸ› ï¸ Detalhes da ImplementaÃ§Ã£o

### 1. `Architecture` Class

A classe `Architecture` (no `CNN_FashionMNIST.ipynb`) foi mantida quase idÃªntica Ã  fornecida, com pequenos ajustes de compatibilidade.

### 2. Uso de Hooks

Os PyTorch Hooks foram registrados nas camadas de interesse (`conv1`, `relu1`, `maxp1`, `flatten`, `fc1`, `relu2`, `fc2`) para inspecionar os tensores de ativaÃ§Ã£o **apÃ³s o forward pass** (`register_forward_hook`).

Isto permitiu:
* Visualizar o mapa de caracterÃ­sticas gerado apÃ³s a convoluÃ§Ã£o (`conv1`).
* Verificar o efeito da nÃ£o-linearidade (ReLU) ao zerar as ativaÃ§Ãµes negativas.
* Observar o *downsampling* espacial do *feature map* apÃ³s o *pooling* (`maxp1`).

---

## ğŸ“Š Resultados e AnÃ¡lise 


### 1. Curvas de Perda (Loss)

O modelo foi treinado por 30 Ã©pocas, alcanÃ§ando uma acurÃ¡cia de validaÃ§Ã£o de aproximadamente **80%**.


> **AnÃ¡lise da ConvergÃªncia:**
> As curvas de perda de treino e validaÃ§Ã£o diminuÃ­ram rapidamente nas primeiras 5 Ã©pocas, convergindo para um platÃ´ em torno de 0.5. A perda de validaÃ§Ã£o acompanhou de perto a perda de treino, indicando que o modelo generalizou bem e nÃ£o apresentou *overfitting* significativo. A baixa complexidade do modelo (poucos filtros) pode ter limitado a acurÃ¡cia mÃ¡xima, mas garantiu uma convergÃªncia estÃ¡vel.
![](img/loss.png)]
> ![](img/accuracy.png)]


### 2. AnÃ¡lise dos Feature Maps


> **InterpretaÃ§Ã£o Visual:**
> O **Filtro #0 da camada `conv1`** parece ter aprendido a detectar bordas verticais ou padrÃµes angulares (como Ã© comum em filtros de baixo nÃ­vel). O **Feature Map apÃ³s `conv1`** mostra essas bordas ativadas. ApÃ³s a **`relu1`**, todos os valores negativos foram zerados, resultando em ativaÃ§Ãµes mais esparsas e um mapa mais escuro. Finalmente, a camada **`maxp1`** reduziu o tamanho do *feature map* (de $24\times24$ para $12\times12$), preservando as ativaÃ§Ãµes mais fortes, o que Ã© visÃ­vel pela semelhanÃ§a do padrÃ£o no mapa reduzido.
> ![](img/features_maps.png)]


---

## ğŸ“º VÃ­deo Explicativo

O vÃ­deo a seguir demonstra o processo de desenvolvimento e detalha a anÃ¡lise visual das ativaÃ§Ãµes da rede:

[https://youtu.be/1A-jYQ8Nq3U]

`
